### Hi thereÔºåWelcome to my Art and Technology Creative SpaceÔºÅ üåèüååüåä
### I'm Derrick / Yuan ManÔºàË¢ÅÊª°Ôºâ ÔºÅüëã

[![Yuan-Man's GitHub stats](https://github-readme-stats-git-masterrstaa-rickstaa.vercel.app/api?username=Yuan-ManX&show_icons=true&theme=radical)](https://github.com/Yuan-ManX/github-readme-stats)
[![Top Langs](https://github-readme-stats-git-masterrstaa-rickstaa.vercel.app/api/top-langs/?username=Yuan-ManX&layout=compact)](https://github.com/Yuan-ManX/github-readme-stats)

### Research & HobbiesÔºö AI, Digital Art, Game, Music, Film, Sound, Code, Design, etc. üé∏üéπü•Åüéªüé∫üé§üéß

- [SouPyX](https://github.com/Yuan-ManX/SouPyX) - Audio Toolkit üéµ

- [ArtNex](https://github.com/Yuan-ManX/artnex) - Deep Learning Framework üöÄ

- [SoundHub](https://github.com/Yuan-ManX/SoundHub) - AI Audio Framework üõ∏

- [DataForm](https://github.com/Yuan-ManX/dataform) - Data Processing Toolkit üî•

- [NexEngine](https://github.com/Yuan-ManX/NexEngine) - Game Engine üéÆ

- [MultiClip](https://github.com/Yuan-ManX/multi-clip) - MultiModal Clip ü§ñ

- [Civitai](https://civitai.com/user/Y_Man) - Open Source AI Models ‚ú®


### AI Research:

- AI Resources
  - Game :  [AI Game DevTools (AI-GDT)](https://github.com/Yuan-ManX/ai-game-development-tools), [AI Native Game](https://github.com/Yuan-ManX/AI-Native-Game), [Game Engine üéÆ](https://github.com/Yuan-ManX/game-engine),
  - Dataset :  [AI Audio Datasets (AI-ADL) üéµ](https://github.com/Yuan-ManX/ai-audio-datasets),
  - LLM :  [LLM App Stack](https://github.com/a16z-infra/llm-app-stack), [ü§ñ Awesome ChatGPT](https://github.com/sindresorhus/awesome-chatgpt),
  - Agent :  [AI Agent Roadmap](https://github.com/Yuan-ManX/ai-agent-roadmap), [AI Voice Agents](https://github.com/Yuan-ManX/ai-voice-agents), [Audio AI Agent](https://github.com/Yuan-ManX/audio-ai-agent),
  - Multimodal :  [AI Multimodal Timeline](https://github.com/Yuan-ManX/ai-multimodal-timeline),
  - Audio :  [Audio AI Timeline](https://github.com/archinetai/audio-ai-timeline), [AI Audio Startups](https://github.com/csteinmetz1/ai-audio-startups), [Audio Development Tools (ADT) üî•](https://github.com/Yuan-ManX/audio-development-tools),[Large Audio Models](https://github.com/liusongxiang/Large-Audio-Models), [üî± Speech Trident](https://github.com/ga642381/speech-trident), [Open-Source Audio Plugins & Apps](https://github.com/webprofusion/OpenAudio), [Awesome Music Informatics](https://github.com/yamathcy/awesome-music-informatics), [AudioLLMs](https://github.com/AudioLLMs/AudioLLM), [Awesome Large Language Models in Audio AI](https://github.com/EmulationAI/awesome-large-audio-models),
  - ComfyUI :  [ComfyUI Tools Roadmap](https://github.com/Yuan-ManX/ComfyUI-Tools-Roadmap),
  - Mamba :  [Awesome State-Space Resources for ML](https://github.com/AvivBick/awesome-ssm-ml),
  - AI-Startups :  [AI Startups üöÄ](https://github.com/Yuan-ManX/AI-Startups), [AI Engineer DevTools](https://github.com/Yuan-ManX/AI-Engineer-DevTools),

- AI Project
  - AI OS :  [01 Project](https://github.com/OpenInterpreter/01),
  - LLama :  [LLama Agentic System](https://github.com/meta-llama/llama-agentic-system),
  - Audio :  [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS), [ChatTTS](https://github.com/2noise/ChatTTS), [StableTTS](https://github.com/KdaiP/StableTTS), [SoundHub](https://github.com/Yuan-ManX/SoundHub), [GLM-4-Voice](https://github.com/THUDM/GLM-4-Voice),
  - Video/Image :  [Open-Sora](https://github.com/hpcaitech/Open-Sora), [DiffSynth Studio](https://github.com/modelscope/DiffSynth-Studio),
  - Avatar :  [Hallo2](https://github.com/fudan-generative-vision/hallo2),
  - AI Search Engine :  [MindSearch](https://github.com/InternLM/MindSearch), [ScrapeGraphAI](https://github.com/VinciGit00/Scrapegraph-ai), [RAGoon](https://github.com/louisbrulenaudet/ragoon), [SearchPhi](https://github.com/AstraBert/SearchPhi),
  - ComfyUI :  [ComfyUI-LLaMA-Mesh](https://github.com/Yuan-ManX/ComfyUI-LLaMA-Mesh), [ComfyUI-SoundHub](https://github.com/Yuan-ManX/ComfyUI-SoundHub), [ComfyUI Manager](https://github.com/ltdrdata/ComfyUI-Manager),
  - LLM/Dataset :  [aisuite](https://github.com/andrewyng/aisuite), [ArtNex](https://github.com/Yuan-ManX/artnex), [DataForm](https://github.com/Yuan-ManX/dataform), [Nexa SDK](https://github.com/NexaAI/nexa-sdk),
  - AI Model :  [Civitai](https://civitai.com/user/Y_Man),
  - PyTorch :   [Flow Matching](https://github.com/facebookresearch/flow_matching), [Stable Diffusion](https://github.com/Yuan-ManX/Stable-Diffusion-PyTorch), [Imagen](https://github.com/Yuan-ManX/Imagen-PyTorch), [FLUX](https://github.com/Yuan-ManX/FLUX-PyTorch), [Diffusion from Scratch](https://github.com/Yuan-ManX/Diffusion-from-Scratch), [LoRA](https://github.com/Yuan-ManX/LoRA-PyTorch), [Diffusion LoRA Fine-Tuning](https://github.com/Yuan-ManX/Diffusion-LoRA-Fine-Tuning), [IP-Adapter](https://github.com/Yuan-ManX/IP-Adapter-PyTorch), [InstantID](https://github.com/Yuan-ManX/InstantID-PyTorch), [Autoregressive Diffusion](https://github.com/Yuan-ManX/Autoregressive-Diffusion), [Audio Diffusion](https://github.com/Yuan-ManX/Audio-Diffusion), [Stable Audio](https://github.com/Yuan-ManX/Stable-Audio-PyTorch), [Riffusion](https://github.com/Yuan-ManX/Riffusion-PyTorch), [AudioLM](https://github.com/Yuan-ManX/AudioLM), [MusicLM](https://github.com/Yuan-ManX/MusicLM), [MusicLLM](https://github.com/Yuan-ManX/MusicLLM-PyTorch), [MusicGen](https://github.com/Yuan-ManX/MusicGen-PyTorch), [MusicGen LoRA](https://github.com/Yuan-ManX/MusicGen-LoRA-PyTorch), [MMAudio](https://github.com/Yuan-ManX/MMAudio-PyTorch), [FoleyCrafter](https://github.com/Yuan-ManX/FoleyCrafter-PyTorch), [FluxMusic](https://github.com/Yuan-ManX/FluxMusic-PyTorch), [TangoFlux](https://github.com/Yuan-ManX/TangoFlux-PyTorch), [SongGen](https://github.com/Yuan-ManX/SongGen-PyTorch), [Text2Midi](https://github.com/Yuan-ManX/Text2Midi-PyTorch), [Midi Transformer](https://github.com/Yuan-ManX/Midi-Transformer), [Audio Diffusion Timbre Transfer](https://github.com/Yuan-ManX/Audio-Diffusion-Timbre-Transfer), [Conformer](https://github.com/Yuan-ManX/Conformer-PyTorch), [Whisper](https://github.com/Yuan-ManX/Whisper-PyTorch), [VALL-E](https://github.com/Yuan-ManX/VALL-E-PyTorch), [NaturalSpeech2](https://github.com/Yuan-ManX/NaturalSpeech2-PyTorch), [Bark](https://github.com/Yuan-ManX/Bark-PyTorch), [Spear-TTS](https://github.com/Yuan-ManX/Spear-TTS), [Spirit LM](https://github.com/Yuan-ManX/SpiritLM-PyTorch), [E2 TTS](https://github.com/Yuan-ManX/E2-TTS), [Voicebox](https://github.com/Yuan-ManX/Voicebox-PyTorch), [Zonos](https://github.com/Yuan-ManX/Zonos-PyTorch), [VITS](https://github.com/Yuan-ManX/VITS-PyTorch), [SoundStream](https://github.com/Yuan-ManX/SoundStream-PyTorch), [EnCodec](https://github.com/Yuan-ManX/EnCodec-PyTorch), [SoundStorm](https://github.com/Yuan-ManX/SoundStorm-PyTorch), [DAC](https://github.com/Yuan-ManX/DAC-PyTorch), [SpeechTokenizer](https://github.com/Yuan-ManX/SpeechTokenizer-PyTorch), [WaveNet](https://github.com/Yuan-ManX/WaveNet-PyTorch), [HiFi-GAN](https://github.com/Yuan-ManX/HiFi-GAN), [MelGAN](https://github.com/Yuan-ManX/MelGAN-PyTorch), [BigVGAN](https://github.com/Yuan-ManX/BigVGAN-PyTorch), [WaveGlow](https://github.com/Yuan-ManX/WaveGlow-PyTorch), [Vocos](https://github.com/Yuan-ManX/Vocos-PyTorch), [GameGen](https://github.com/Yuan-ManX/GameGen-PyTorch), [Genie2](https://github.com/Yuan-ManX/Genie2-PyTorch), [MeshGPT](https://github.com/Yuan-ManX/MeshGPT-PyTorch), [NeRF](https://github.com/Yuan-ManX/NeRF-PyTorch), [RVQ](https://github.com/Yuan-ManX/RVQ-PyTorch), [FSQ](https://github.com/Yuan-ManX/FSQ-PyTorch), [VQ](https://github.com/Yuan-ManX/VQ-PyTorch), [VAE](https://github.com/Yuan-ManX/VAE-PyTorch), [Distributed VAE Trainer](https://github.com/Yuan-ManX/Distributed-VAE-Trainer), [VQ-VAE-2](https://github.com/Yuan-ManX/VQ-VAE-2), [BPE](https://github.com/Yuan-ManX/BPE), [RoPE](https://github.com/Yuan-ManX/RoPE-PyTorch), [GPT](https://github.com/Yuan-ManX/GPT-PyTorch), [LLaMA](https://github.com/Yuan-ManX/LLaMA-PyTorch), [ViT](https://github.com/Yuan-ManX/ViT-PyTorch), [Transfusion](https://github.com/Yuan-ManX/Transfusion-PyTorch), [MMDiT](https://github.com/Yuan-ManX/MMDiT-PyTorch), [CFG](https://github.com/Yuan-ManX/CFG-PyTorch), [CLIP](https://github.com/Yuan-ManX/CLIP-PyTorch), [MuQ-MuLan](https://github.com/Yuan-ManX/MuQ-PyTorch), [LLaVA](https://github.com/Yuan-ManX/LLaVA-PyTorch), [MoE](https://github.com/Yuan-ManX/MoE-PyTorch), [Mamba](https://github.com/Yuan-ManX/Mamba-PyTorch), [Vision Mamba](https://github.com/Yuan-ManX/VisionMamba-PyTorch), [Jamba](https://github.com/Yuan-ManX/Jamba-PyTorch), [Titans](https://github.com/Yuan-ManX/Titans-PyTorch), [Mind Evolution](https://github.com/Yuan-ManX/Mind-Evolution-PyTorch), [DeepCrossAttention](https://github.com/Yuan-ManX/DeepCrossAttention-PyTorch), [Native Sparse Attention](https://github.com/Yuan-ManX/NativeSparseAttention-PyTorch), [PPO](https://github.com/Yuan-ManX/PPO-PyTorch), [GRPO](https://github.com/Yuan-ManX/GRPO-PyTorch),
  - Tool :  [FastHTML](https://github.com/AnswerDotAI/fasthtml), [SouPyX](https://github.com/Yuan-ManX/SouPyX),

### I love everything I loveÔºÅ
### ‚ÄúÊó•Êó•Ë°å‰∏çÊÄïÂçÉ‰∏áÈáåÔºåÊó∂Êó∂ÂÅö‰∏çÊÉßÂçÉ‰∏á‰∫ã„ÄÇ‚Äù


<!--
**Yuan-ManX/Yuan-ManX** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->
